{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Anomaly Detection for BNG Subscriber Traffic\n",
        "\n",
        "This notebook demonstrates how to connect to the InfluxDB database, query subscriber traffic data, and use the **Isolation Forest** algorithm to detect anomalies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from influxdb_client import InfluxDBClient\n",
        "from sklearn.ensemble import IsolationForest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Configure InfluxDB Connection\n",
        "\n",
        "First, we'll initialize the InfluxDB client by reading the connection details from environment variables. This is a best practice for security and portability, as it avoids hardcoding credentials in the notebook. These variables are passed to the Jupyter container by `docker-compose`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- InfluxDB Connection Details ---\n",
        "INFLUXDB_URL = os.getenv(\"INFLUXDB_URL\", \"http://localhost:8086\")\n",
        "INFLUXDB_TOKEN = os.getenv(\"INFLUXDB_TOKEN\", \"my-super-secret-bng-token\")\n",
        "INFLUXDB_ORG = os.getenv(\"INFLUXDB_ORG\", \"bng-telemetry-org\")\n",
        "INFLUXDB_BUCKET = os.getenv(\"INFLUXDB_BUCKET\", \"bng-bucket\")\n",
        "\n",
        "# --- Initialize Client ---\n",
        "client = InfluxDBClient(url=INFLUXDB_URL, token=INFLUXDB_TOKEN, org=INFLUXDB_ORG)\n",
        "query_api = client.query_api()\n",
        "\n",
        "print(\"InfluxDB client initialized.\")\n",
        "print(f\"URL: {INFLUXDB_URL}\")\n",
        "print(f\"Org: {INFLUXDB_ORG}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Query Subscriber Data\n",
        "\n",
        "Next, we define a Flux query to retrieve the total `input_octets` for each subscriber over the last hour. The `increase()` function is perfect for this, as it calculates the growth of a counter over a time window."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Define the Flux Query ---\n",
        "flux_query = f'''\n",
        "from(bucket: \"{INFLUXDB_BUCKET}\")\n",
        "  |> range(start: -1h)\n",
        "  |> filter(fn: (r) => r[\\\"_measurement\\\"] == \\\"bng_subscriber_stats\\\")\n",
        "  |> filter(fn: (r) => r[\\\"_field\\\"] == \\\"input_octets\\\")\n",
        "  |> increase()\n",
        "  |> group(columns: [\\\"mac\\\"])\n",
        "  |> sum()\n",
        "  |> keep(columns: [\\\"_value\\\", \\\"mac\\\"])\n",
        "'''\n",
        "\n",
        "print(\"Flux query defined:\")\n",
        "print(flux_query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Execute the query and load into a Pandas DataFrame ---\n",
        "print(\"Querying InfluxDB...\")\n",
        "result_df = query_api.query_data_frame(query=flux_query)\n",
        "\n",
        "# Clean up the DataFrame\n",
        "if not result_df.empty:\n",
        "    result_df = result_df.rename(columns={\"_value\": \"total_input_octets\"})\n",
        "    result_df = result_df.drop(columns=[\"result\", \"table\"], errors='ignore')\n",
        "    result_df = result_df.set_index('mac')\n",
        "    print(f\"Successfully loaded {len(result_df)} records into a DataFrame.\")\n",
        "else:\n",
        "    print(\"Warning: Query returned no data. Ensure the simulator is running and generating data.\")\n",
        "\n",
        "result_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Apply Isolation Forest for Anomaly Detection\n",
        "\n",
        "The **Isolation Forest** is an unsupervised learning algorithm that's well-suited for anomaly detection. It works by \"isolating\" observations by randomly selecting a feature and then randomly selecting a split value. Since anomalies are \"few and different,\" they are easier to isolate and should have shorter average path lengths in the random decision trees.\n",
        "\n",
        "We will apply this model to the `total_input_octets` to find subscribers with unusually high or low traffic compared to the majority."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not result_df.empty:\n",
        "    # --- Prepare the data ---\n",
        "    X = result_df[['total_input_octets']].values\n",
        "\n",
        "    # --- Initialize and fit the model ---\n",
        "    # `contamination` is the expected proportion of outliers. 'auto' is a robust default.\n",
        "    model = IsolationForest(contamination='auto', random_state=42)\n",
        "    result_df['anomaly_score'] = model.fit_predict(X)\n",
        "\n",
        "    # The model returns -1 for anomalies and 1 for inliers.\n",
        "    print(\"Anomaly scores calculated. (-1 for anomalies, 1 for inliers)\")\n",
        "    print(result_df['anomaly_score'].value_counts())\n",
        "else:\n",
        "    print(\"DataFrame is empty. Skipping model training.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Identify and Display Anomalies\n",
        "\n",
        "Finally, we filter the DataFrame to show only the subscribers that the model has flagged as anomalous."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not result_df.empty:\n",
        "    # --- Filter for anomalies ---\n",
        "    anomalies = result_df[result_df['anomaly_score'] == -1]\n",
        "\n",
        "    print(\"\\n--- Detected Anomalies ---\")\n",
        "    if not anomalies.empty:\n",
        "        print(f\"Found {len(anomalies)} anomalous subscribers:\")\n",
        "        print(anomalies)\n",
        "    else:\n",
        "        print(\"No anomalies detected in this time window.\")\n",
        "else:\n",
        "    print(\"DataFrame is empty. No anomalies to report.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}